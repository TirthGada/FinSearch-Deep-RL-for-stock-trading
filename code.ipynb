{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import yfinance as yf\n",
    "\n",
    "# Define StockTradingEnv class\n",
    "class StockTradingEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.max_steps = len(data)\n",
    "        self.current_step = None\n",
    "        self.action_space = gym.spaces.Discrete(3)  # Buy, Sell, Hold\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(5,))\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = 10000\n",
    "        self.shares_held = 0\n",
    "        self.net_worth = self.balance\n",
    "        self.stock_price = self.data['close'][self.current_step]\n",
    "        self.history = np.array([self.balance, self.shares_held, self.stock_price, 0, 0])\n",
    "        return self.history\n",
    "\n",
    "    def step(self, action):\n",
    "        self._take_action(action)\n",
    "        self.current_step += 1\n",
    "        self.stock_price = self.data['close'][self.current_step]\n",
    "        self.net_worth = self.balance + self.shares_held * self.stock_price\n",
    "        self.history = np.array([self.balance, self.shares_held, self.stock_price, self.net_worth, action])\n",
    "        reward = self.net_worth - self.history[3]\n",
    "        done = self.current_step == self.max_steps - 1\n",
    "        return self.history, reward, done, {}\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        if action == 0:  # Buy\n",
    "            self.shares_held += 100\n",
    "            self.balance -= self.stock_price * 100\n",
    "        elif action == 1:  # Sell\n",
    "            self.shares_held -= 100\n",
    "            self.balance += self.stock_price * 100\n",
    "\n",
    "# Define DQNAgent class\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Dense(24, input_dim=self.state_size, activation='relu'),\n",
    "            layers.Dense(24, activation='relu'),\n",
    "            layers.Dense(self.action_size, activation='linear')\n",
    "        ])\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward + 0.95 * np.amax(self.model.predict(next_state)[0])\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "# Retrieve and save stock data\n",
    "symbol = 'AAPL'\n",
    "start_date = '2023-07-01'\n",
    "end_date = '2023-08-10'\n",
    "\n",
    "def get_stock_data(symbol, start_date, end_date):\n",
    "    stock = yf.download(symbol, start=start_date, end=end_date)\n",
    "    stock.reset_index(inplace=True)\n",
    "    stock.rename(columns={'Date': 'date', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'}, inplace=True)\n",
    "    return stock[['date', 'close']]\n",
    "\n",
    "stock_data = get_stock_data(symbol, start_date, end_date)\n",
    "stock_data.to_csv('stock_data.csv', index=False)\n",
    "\n",
    "# Create the environment\n",
    "data = pd.read_csv('stock_data.csv')\n",
    "env = StockTradingEnv(data)\n",
    "\n",
    "# Initialize the DQNAgent\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 100\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "\n",
    "    for step in range(env.max_steps):\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.train(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(f\"Episode: {episode}/{num_episodes}, Net Worth: {env.net_worth}\")\n",
    "            break\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "def fit_arima(data):\n",
    "    # Fit an ARIMA model to historical stock price data\n",
    "    # 'data' should be a pandas Series or DataFrame with the historical stock prices\n",
    "    # You can adjust the order (p, d, q) of the ARIMA model based on your data and needs\n",
    "    p, d, q = 1, 1, 1  # Example values, you might need to adjust these\n",
    "    arima_model = ARIMA(data, order=(p, d, q))\n",
    "    arima_model_fit = arima_model.fit()\n",
    "    return arima_model_fit\n",
    "\n",
    "def forecast_arima(model, steps):\n",
    "    # Generate ARIMA forecasts for the next 'steps' time steps\n",
    "    # 'model' should be the ARIMA model fitted using fit_arima\n",
    "    # 'steps' is the number of steps into the future you want to forecast\n",
    "    arima_forecasts = model.forecast(steps=steps)\n",
    "    return arima_forecasts\n",
    "    \n",
    "    \n",
    "\n",
    "# Using ARIMA forecasts for trading decisions\n",
    "forecast_steps = 10 \n",
    "arima_model_fit = fit_arima(stock_data['close'])\n",
    "arima_forecasts = forecast_arima(arima_model_fit, forecast_steps)\n",
    "\n",
    "% Combine ARIMA forecasts with RL environment\n",
    "for i in range(len(arima_forecasts)):\n",
    "    state = env.history\n",
    "    state[2] = arima_forecasts[i]\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    next_state = np.reshape(next_state, [1, state_size])\n",
    "    agent.train(state, action, reward, next_state, done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
